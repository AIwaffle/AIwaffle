{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a experimental course of project [AIwaffle](https://github.com/AIwaffle/AIwaffle), an AI learning platform completely made by high school students\n",
    "Check out our [github repo](https://github.com/AIwaffle/AIwaffle) and www.aiwaffle.com for more information\n",
    "\n",
    "Author: Yinjie Xu, Yulun Wu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Tools\n",
    "In practice, it should be hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_hint():\n",
    "    print(\n",
    "    \"\"\"\n",
    "    trainDataset = MNISTDataset(\"../input/mnist-in-csv/mnist_train.csv\")\n",
    "    trainDataloader = torch.utils.data.DataLoader(trainDataset, batch_size=10, shuffle=True)\n",
    "    testDataset = MNISTDataset(\"../input/mnist-in-csv/mnist_test.csv\")\n",
    "    testDataloader = torch.utils.data.DataLoader(testDataset, batch_size=10000)\n",
    "    \"\"\"\n",
    "    )\n",
    "def q2_hint():\n",
    "    print(\n",
    "    \"\"\"\n",
    "    def fit(model, epochs):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        overall_loss = 0\n",
    "        for i, (X, Y) in enumerate(trainDataloader):\n",
    "            Y_pred = model(X)S\n",
    "            loss = loss_fn(Y_pred, Y)\n",
    "            overall_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if i % 1000 == 999:\n",
    "                print(f'in epoch {epoch}, batch {i+1}, loss = {overall_loss / 1000}')\n",
    "                overall_loss = 0.\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "def q3_hint():\n",
    "    print(\n",
    "    \"\"\"model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10))\n",
    "fit(model, 1)\n",
    "val(model)\n",
    "    \"\"\"\n",
    "    )\n",
    "def q4_hint():\n",
    "    print(\n",
    "    \"\"\"\n",
    "    model = nn.Sequential(\n",
    "    Preprocess(),\n",
    "    nn.Conv2d(1, 32, 3),# 26 * 26 * 32\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),# 13 * 13 * 32\n",
    "    nn.Conv2d(32, 16, 5),# 9 * 9 S* 16\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3),# 3 * 3 * 16\n",
    "    nn.Conv2d(16, 10, 3),# 1 * 1 * 10\n",
    "    nn.Flatten())\n",
    "fit(model, 1)\n",
    "val(model)\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Body\n",
    "* Fill out `None` and `pass` to proceed  \n",
    "* Uncomment `qx_hint` to see the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import os\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One method for loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "mnist_test = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\n",
    "mnist_train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\n",
    "train_Y = mnist_train.iloc[:, 0].values\n",
    "train_X = mnist_train.iloc[:, 1:].values\n",
    "test_Y = mnist_test.iloc[:, 0].values\n",
    "test_X = mnist_test.iloc[:, 1:].values\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ## Another method - using torch.Dataset\n",
    "you \n",
    "A batch will be `List[Dict]` with keys \"image\", \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to use:  \n",
    "https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "#create self-defining data\n",
    "class MNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, transform=None): #Some initialization\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self): #Returns the amount of all data\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index): #Return data and labels\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "            \n",
    "        image = self.dataframe.iloc[index, 1:].values.astype('float32')\n",
    "        #print(type(self.dataframe.iloc[index, 0]))\n",
    "        label = self.dataframe.iloc[index, 0]\n",
    "        image = image.reshape((28, 28))\n",
    "        # Normalize TODO:use transform to do it\n",
    "        image = (image - image.mean()) / image.std()\n",
    "        return image, label\n",
    "\n",
    "#1.Create dataset for both CtrainDataset and testDataset\n",
    "#2.Use torch.utils.data.DataLoader to make some batches. You can think of it as a packaging process.\n",
    "#example = torch.utils.data.DataLoader(dataset=trainDataset, batch_size=10,shuffle=True)\n",
    "trainDataset = None\n",
    "trainDataloader = None\n",
    "testDataset = None\n",
    "testDataloader = None\n",
    "\n",
    "#q1_hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the code below to inspect your data\n",
    "plt.figure(figsize=(3, 3))\n",
    "i = 1\n",
    "plt.gca().invert_yaxis()\n",
    "plt.pcolormesh(trainDataset[i][0])\n",
    "print(trainDataset[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function: fit(), val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a fitting network\n",
    "def fit(model, epochs):\n",
    "    pass#Define the optimizer like SGD\n",
    "    pass#Define the loss function\n",
    "    for epoch in range(epochs):\n",
    "        overall_loss = 0\n",
    "        for i, (X, Y) in enumerate(trainDataloader):\n",
    "            pass#The forward propagation\n",
    "            pass#Count the loss\n",
    "            pass#Accumulative the loss\n",
    "            pass#The back Propagation\n",
    "            pass#Update the gradient\n",
    "            pass#Don't forget to clear the gradient\n",
    "            if i % 1000 == 999:\n",
    "                print(f'in epoch {epoch}, batch {i+1}, loss = {overall_loss / 1000}')\n",
    "                overall_loss = 0.\n",
    "            \n",
    "def val(model):\n",
    "    for X, Y in testDataloader:\n",
    "        Y_pred = model(X).argmax(dim=1)\n",
    "        rightCount = (Y == Y_pred).sum().item()\n",
    "        accuracy = rightCount / 10000\n",
    "        print(\"accuracy =\", accuracy)\n",
    "        \n",
    "#q2_hint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Network 88%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 10)\n",
    ")\n",
    "fit(model, 1)\n",
    "val(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Network 95.24%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to use:  \n",
    "https://pytorch.org/docs/stable/nn.html#sequential  \n",
    "https://pytorch.org/docs/stable/nn.html#flatten  \n",
    "https://pytorch.org/docs/stable/nn.html#linear    \n",
    "https://pytorch.org/docs/stable/nn.html#relu  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    #First you need a flatten layer \n",
    "    pass\n",
    "    #Then you need to create the linear transformation from the input layer to the hidden layer\n",
    "    pass\n",
    "    #Then the activation function\n",
    "    pass\n",
    "    #Then the linear transformation from the hidden layer to the output layer\n",
    "    pass\n",
    ")\n",
    "fit(model, 1)\n",
    "val(model)\n",
    "\n",
    "#q3_hint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 97.85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to use:  \n",
    "https://pytorch.org/docs/stable/nn.html#module  \n",
    "https://pytorch.org/docs/stable/nn.html#conv2d  \n",
    "https://pytorch.org/docs/stable/nn.html#adaptivemaxpool2d  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CNN architecture generally consists of the following layers:\n",
    "* Convolutional layer: used for feature extraction and feature mapping\n",
    "* ReLU layer: used to increase nonlinearity\n",
    "* Pooling layer: sampling and sparse processing of feature map to reduce the loss of feature information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Preprocess, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A CNN architecture generally consists of the following layers:\n",
    "# Convolutional layer: used for feature extraction and feature mapping\n",
    "# ReLU layer: used to increase nonlinearity\n",
    "# Pooling layer: sampling and sparse processing of feature map to reduce the loss of feature information\n",
    "# Fully connected layer\n",
    "\n",
    "pass\n",
    "\n",
    "#q4_hint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well done!\n",
    "Check out our [github repo](https://github.com/AIwaffle/AIwaffle) for more information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
